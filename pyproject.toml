[project]
name = "tritter"
version = "0.2.0"
description = "Multimodal AI model with BitNet 1.58-bit quantization, 128K context, any-to-any (text/code/image/audio) fusion"
readme = "README.md"
requires-python = ">=3.12,<3.14"
license = {text = "MIT"}
authors = [
    {name = "Tyler Zervas", email = "tz-dev@vectorweight.com"}
]
keywords = [
    "bitnet",
    "multimodal",
    "ternary-quantization",
    "transformer",
    "ai",
    "deep-learning"
]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]

dependencies = [
    # NOTE: For RTX 50-series (Blackwell, SM_120), install PyTorch nightly separately:
    #   uv pip install torch triton --pre --index-url https://download.pytorch.org/whl/nightly/cu128
    # Pinned nightly version with sm_120 support: torch==2.11.0.dev20260123+cu128
    # See docs/HARDWARE_REQUIREMENTS.md and docs/adr/004-blackwell-gpu-support.md
    "torch>=2.5.0",
    "numpy>=1.24.0",
    "transformers>=4.35.0",
    "tokenizers>=0.15.0",
    "tiktoken>=0.5.0",
    "einops>=0.7.0",
    "triton>=3.0.0",
    "tree-sitter>=0.20.0",
    "tree-sitter-python>=0.20.0",
    "tree-sitter-rust>=0.20.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "ruff>=0.1.0",
    "mypy>=1.7.0",
    "pre-commit>=3.6.0",
]

extras = [
    "faiss-cpu>=1.8.0",
    "safetensors>=0.4.3",
]

inference = [
    "vllm>=0.6.0",
]

training = [
    "nanotron>=0.3.0",
    "vsa-training-optimizer>=0.1.0",  # VSA/ternary gradient optimization
]

curation = [
    "datasketch>=1.6.0",  # For efficient MinHash deduplication
]

all = [
    "tritter[dev,inference,training,curation,extras]",
]

[project.scripts]
tritter-validate = "devtools.validate:main"
tritter-status = "devtools.project_info:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/tritter", "devtools"]

[tool.ruff]
line-length = 100
target-version = "py312"

[tool.ruff.lint]
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # pyflakes
    "I",   # isort
    "B",   # flake8-bugbear
    "C4",  # flake8-comprehensions
    "UP",  # pyupgrade
]
ignore = [
    "E501",  # line too long, handled by formatter
    "B008",  # do not perform function calls in argument defaults
]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.mypy]
python_version = "3.12"
strict = true
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_any_generics = false
ignore_missing_imports = true

[tool.pytest.ini_options]
minversion = "7.0"
addopts = "-ra -q --strict-markers"
testpaths = [
    "tests",
]
pythonpath = [
    "src",
    "."
]
markers = [
    "gpu: marks tests as requiring GPU hardware (deselect with '-m \"not gpu\"')",
    "slow: marks tests as slow running (deselect with '-m \"not slow\"')",
]
filterwarnings = [
    "ignore:`torch.nn.utils.weight_norm` is deprecated:FutureWarning",
    "ignore:`torch.jit.script_method` is deprecated:DeprecationWarning",
    "ignore:The argument 'device' of Tensor.pin_memory\\(\\) is deprecated:DeprecationWarning",
    "ignore:The argument 'device' of Tensor.is_pinned\\(\\) is deprecated:DeprecationWarning",
    "ignore:Detected call of `lr_scheduler.step\\(\\)` before `optimizer.step\\(\\)`:UserWarning",
]

[tool.coverage.run]
source = ["src"]
omit = ["tests/*"]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
]
